{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2 ——Climate Change\n",
    "### 1801212920 史云霞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1 —Creating Your First Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in how changes in these variables affect future temperatures, as well\n",
    "as how well these variables explain temperature changes so far. To do this, first read the\n",
    "dataset climate_change_1.csv into Python or Matlab.\n",
    "\n",
    "Then, split the data into a training set, consisting of all the observations up to and\n",
    "including 2006, and a testing set consisting of the remaining years. A training set refers\n",
    "to the data that will be used to build the model, and a testing set refers to the data we\n",
    "will use to test our predictive ability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>MEI</th>\n",
       "      <th>CO2</th>\n",
       "      <th>CH4</th>\n",
       "      <th>N2O</th>\n",
       "      <th>CFC-11</th>\n",
       "      <th>CFC-12</th>\n",
       "      <th>TSI</th>\n",
       "      <th>Aerosols</th>\n",
       "      <th>Temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1983</td>\n",
       "      <td>5</td>\n",
       "      <td>2.556</td>\n",
       "      <td>345.96</td>\n",
       "      <td>1638.59</td>\n",
       "      <td>303.677</td>\n",
       "      <td>191.324</td>\n",
       "      <td>350.113</td>\n",
       "      <td>1366.1024</td>\n",
       "      <td>0.0863</td>\n",
       "      <td>0.109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1983</td>\n",
       "      <td>6</td>\n",
       "      <td>2.167</td>\n",
       "      <td>345.52</td>\n",
       "      <td>1633.71</td>\n",
       "      <td>303.746</td>\n",
       "      <td>192.057</td>\n",
       "      <td>351.848</td>\n",
       "      <td>1366.1208</td>\n",
       "      <td>0.0794</td>\n",
       "      <td>0.118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1983</td>\n",
       "      <td>7</td>\n",
       "      <td>1.741</td>\n",
       "      <td>344.15</td>\n",
       "      <td>1633.22</td>\n",
       "      <td>303.795</td>\n",
       "      <td>192.818</td>\n",
       "      <td>353.725</td>\n",
       "      <td>1366.2850</td>\n",
       "      <td>0.0731</td>\n",
       "      <td>0.137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1983</td>\n",
       "      <td>8</td>\n",
       "      <td>1.130</td>\n",
       "      <td>342.25</td>\n",
       "      <td>1631.35</td>\n",
       "      <td>303.839</td>\n",
       "      <td>193.602</td>\n",
       "      <td>355.633</td>\n",
       "      <td>1366.4202</td>\n",
       "      <td>0.0673</td>\n",
       "      <td>0.176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1983</td>\n",
       "      <td>9</td>\n",
       "      <td>0.428</td>\n",
       "      <td>340.17</td>\n",
       "      <td>1648.40</td>\n",
       "      <td>303.901</td>\n",
       "      <td>194.392</td>\n",
       "      <td>357.465</td>\n",
       "      <td>1366.2335</td>\n",
       "      <td>0.0619</td>\n",
       "      <td>0.149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Month    MEI     CO2      CH4      N2O   CFC-11   CFC-12        TSI  \\\n",
       "0  1983      5  2.556  345.96  1638.59  303.677  191.324  350.113  1366.1024   \n",
       "1  1983      6  2.167  345.52  1633.71  303.746  192.057  351.848  1366.1208   \n",
       "2  1983      7  1.741  344.15  1633.22  303.795  192.818  353.725  1366.2850   \n",
       "3  1983      8  1.130  342.25  1631.35  303.839  193.602  355.633  1366.4202   \n",
       "4  1983      9  0.428  340.17  1648.40  303.901  194.392  357.465  1366.2335   \n",
       "\n",
       "   Aerosols   Temp  \n",
       "0    0.0863  0.109  \n",
       "1    0.0794  0.118  \n",
       "2    0.0731  0.137  \n",
       "3    0.0673  0.176  \n",
       "4    0.0619  0.149  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "climate_change_1 = pd.read_csv(\"climate_change_1.csv\")\n",
    "climate_change_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = climate_change_1[climate_change_1['Year'] <= 2006]\n",
    "testing_set = climate_change_1[climate_change_1['Year'] > 2006]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can apply a linear regression model. Though being a little doubtful, you decide to have a try. To\n",
    "solve the linear regression problem, you recall the linear regression has a closed form\n",
    "solution.\n",
    "\n",
    "\\begin{array}{ll} \\mbox{} & \\theta = (X^T X)^{-1} X^X Y\n",
    "\\end{array}\n",
    "\n",
    "#### 1. Implement a function closed_form_1 that computes this closed form solution given the features X, labels Y (using Python or Matlab)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closed_form_1(X, Y):\n",
    "    X = np.hstack((np.ones([X.shape[0], 1]), X)) # intercept\n",
    "    theta = np.linalg.inv(X.T @ X) @ X.T @ Y\n",
    "    \n",
    "    MSE = (Y - X@theta).T @ (Y - X@theta) / (X.shape[0]-X.shape[1])\n",
    "    t_stat = theta / (np.sqrt(MSE * np.diag(np.linalg.inv(X.T @ X))))\n",
    "    return theta, t_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Write down the mathematical formula for the linear model and evaluate the model R2 on the training set and the testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear model:\n",
    "\\begin{array}{ll} \\mbox{} & Y = X \\theta + \\epsilon, \\epsilon \\sim (0, \\sigma^2 I)\n",
    "\\end{array}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def R2(Y, Y_predict):\n",
    "    SST = np.sum((Y - Y.mean())**2)\n",
    "    SSR = np.sum((Y_predict - Y.mean())**2)\n",
    "    return SSR / SST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model R2 on the training set and the testing set are 0.750893 and 0.225177.\n"
     ]
    }
   ],
   "source": [
    "theta, t_stat = closed_form_1(training_set.loc[:, \"MEI\":\"Aerosols\"].values, training_set[\"Temp\"].values)\n",
    "y_predict = training_set.loc[:, \"MEI\":\"Aerosols\"] @ theta[1:] + theta[0]\n",
    "R2_training = R2(training_set[\"Temp\"], y_predict)\n",
    "\n",
    "y_predict = testing_set.loc[:, \"MEI\":\"Aerosols\"] @ theta[1:] + theta[0]\n",
    "R2_testing = R2(testing_set[\"Temp\"], y_predict)\n",
    "\n",
    "print(\"The model R2 on the training set and the testing set are %f and %f.\" % (R2_training, R2_testing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Which variables are significant in the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1.24594261e+02,  6.42053134e-02,  6.45735927e-03,  1.24041896e-04,\n",
       "        -1.65280033e-02, -6.63048889e-03,  3.80810324e-03,  9.31410838e-02,\n",
       "        -1.53761324e+00]),\n",
       " array([-6.26517396,  9.923226  ,  2.8264197 ,  0.2404694 , -1.92972604,\n",
       "        -4.07783387,  3.75729271,  6.31256095, -7.21030085]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta, t_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MEI', 'CO2', 'CFC-11', 'CFC-12', 'TSI', 'Aerosols'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.loc[:, \"MEI\":\"Aerosols\"].columns[np.abs(t_stat[1:]) >= 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above result, we can see that MEI, CO2, CFC-11, CFC-12, TSI and Aerosols variables are significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Write down the necessary conditions for using the closed form solution. And you can apply it to the dataset climate_change_2.csv, explain the solution is unreasonable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessary condition for using the closed form solution is that X'X is invertible, which means there can't be redundant varibles or too many variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_change_2 = pd.read_csv(\"climate_change_2.csv\")\n",
    "training_set2 = climate_change_2[climate_change_2['Year'] <= 2006]\n",
    "testing_set2 = climate_change_2[climate_change_2['Year'] > 2006]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.80264006e+01  6.76756906e-02  5.95210064e-03  5.64175439e-02\n",
      " -1.65280032e-02 -6.63048889e-03  3.80810324e-03  9.31410841e-02\n",
      " -1.53761324e+00 -5.62567601e+01] \n",
      " [-1.72117564e-04  4.40545033e+00  1.09730578e+00  1.42745318e-04\n",
      " -8.12776911e-01 -1.71753355e+00  1.58252555e+00  2.65877315e+00\n",
      " -3.03689017e+00 -1.42338510e-04]\n"
     ]
    }
   ],
   "source": [
    "theta, t_stat = closed_form_1(training_set2.loc[:, \"MEI\":\"NO\"].values, training_set2[\"Temp\"].values)\n",
    "print(theta, \"\\n\", t_stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When applying closed form solution to the dataset climate_change_2.csv, we can see that the abs(coefficient) of NO variable is relatively high compared with others and the t statistics is not significant. So this solution is unreasonable to this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The eigen values of X'X in climate_change_2: \n",
      " [1.54850519e+09 9.67853660e+05 4.51064771e+04 1.26018339e+04\n",
      " 1.58821305e+03 2.37501085e+02 1.07887353e+02 1.89444365e-01\n",
      " 4.25347852e-05 5.08673684e-11]\n"
     ]
    }
   ],
   "source": [
    "X = training_set2.loc[:, \"MEI\":\"NO\"].values.copy()\n",
    "X = np.hstack((np.ones([X.shape[0], 1]), X))\n",
    "print(\"The eigen values of X'X in climate_change_2: \\n\", np.linalg.eig(X.T @ X)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that some eigen values of X'X in climate_change_2 is very close to 0, which indicates there may be\n",
    "strong multicollinearity problems and makes the solution unreasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2 — Regularization\n",
    "Regularization is a method to boost robustness of model, including L1 regularization\n",
    "and L2 regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Please write down the loss function for linear model with L1 regularization, L2 regularization, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The loss function for linear model with L1 regularization\n",
    "\\begin{array}{ll} \\mbox{} & loss = 1/2 (Y - X \\theta)^ T (Y - X \\theta) + \\lambda ||\\theta||_1\n",
    "\\end{array}\n",
    "\n",
    "* The loss function for linear model with L2 regularization\n",
    "\\begin{array}{ll} \\mbox{} & loss = 1/2(Y - X \\theta)^ T (Y - X \\theta) + 1/2 \\lambda ||\\theta||_2^2\n",
    "\\end{array}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. The closed form solution for linear model with L2 regularization:\n",
    "\\begin{array}{ll} \\mbox{} & \\theta = (X^T X + \\lambda I)^{-1} X^T Y\n",
    "\\end{array}\n",
    "\n",
    "where I is the identity matrix. Write a function closed_form_2 that computes this\n",
    "closed form solution given the features X, labels Y and the regularization\n",
    "parameter λ (using Python or Matlab)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closed_form_2(X, Y, lam=0):\n",
    "    X = np.hstack((np.ones([X.shape[0], 1]), X))\n",
    "    temp = lam*np.eye(X.shape[1])\n",
    "#     temp[0, 0] = 1\n",
    "    theta = np.linalg.inv(X.T @ X + temp) @ X.T @ Y\n",
    "    \n",
    "    MSE = (Y - X@theta).T @ (Y - X@theta) / (X.shape[0]-X.shape[1])\n",
    "    t_stat = theta / (np.sqrt(MSE * np.diag(np.linalg.inv(X.T @ X))))\n",
    "    return theta, t_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Compare the two solutions in problem 1 and problem 2 and explain the reason why linear model with L2 regularization is robust. (using climate_change_1.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 2 norm of coefficients in OSL regression is 2.3774254085768325\n",
      "The 2 norm of coefficients in ridge regression is 0.002621399210510632\n"
     ]
    }
   ],
   "source": [
    "theta1, t_stat1 = closed_form_1(training_set.loc[:, \"MEI\":\"Aerosols\"].values, training_set[\"Temp\"].values)\n",
    "theta2, t_stat2 = closed_form_2(training_set.loc[:, \"MEI\":\"Aerosols\"].values, training_set[\"Temp\"].values, lam=10)\n",
    "print(\"The 2 norm of coefficients in OSL regression is\", np.sum(theta1[1:]**2))\n",
    "print(\"The 2 norm of coefficients in ridge regression is\", np.sum(theta2[1:]**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the 2 norm of coefficients in ridge regression is much smaller than that in OLS regression, which means the predicted y will be less sensitive to the change of the features. So ridge regression is more robust."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. You can change the regularization parameter λ to get different solutions for this problem. \n",
    "Suppose we set λ = 10, 1, 0.1, 0.01, 0.001, and please evaluate the\n",
    "model R2 on the training set and the testing set. Finally, please decide the best\n",
    "regularization parameter λ. (Note that: As a qualified data analyst, you must\n",
    "know how to choose model parameters, please learn about cross validation\n",
    "methods.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam_all = [0, 0.01, 0.1, 1, 10, 20]\n",
    "# lam_all = [10, 1, 0.1]\n",
    "R2_training, R2_testing = [], []\n",
    "for each in lam_all:\n",
    "    theta, t_stat = closed_form_2(training_set.loc[:, \"MEI\":\"Aerosols\"].values, training_set[\"Temp\"].values, lam=each)\n",
    "    y_predict = training_set.loc[:, \"MEI\":\"Aerosols\"] @ theta[1:] + theta[0]\n",
    "    R2_training.append(R2(training_set[\"Temp\"], y_predict))\n",
    "\n",
    "    y_predict = testing_set.loc[:, \"MEI\":\"Aerosols\"] @ theta[1:] + theta[0]\n",
    "    R2_testing.append(R2(testing_set[\"Temp\"], y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0</th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.1</th>\n",
       "      <th>1.0</th>\n",
       "      <th>10.0</th>\n",
       "      <th>20.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>R2 traning</th>\n",
       "      <td>0.750893</td>\n",
       "      <td>0.711653</td>\n",
       "      <td>0.694468</td>\n",
       "      <td>0.679469</td>\n",
       "      <td>0.674608</td>\n",
       "      <td>0.670752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2 testing</th>\n",
       "      <td>0.225177</td>\n",
       "      <td>0.585276</td>\n",
       "      <td>0.673288</td>\n",
       "      <td>0.846750</td>\n",
       "      <td>0.940872</td>\n",
       "      <td>0.985088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0.00      0.01      0.10      1.00      10.00     20.00\n",
       "R2 traning  0.750893  0.711653  0.694468  0.679469  0.674608  0.670752\n",
       "R2 testing  0.225177  0.585276  0.673288  0.846750  0.940872  0.985088"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([R2_training, R2_testing], index=[\"R2 traning\", \"R2 testing\"], columns=lam_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use 5-fold cross validation method to choose the model with the lowest Mean Square error in validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model = LinearRegression()\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "X = training_set.loc[:, \"MEI\":\"Aerosols\"].values\n",
    "y = training_set[\"Temp\"].values\n",
    "\n",
    "lam_all = [0, 0.001, 0.01, 0.1, 1, 10, 20]\n",
    "MSE_training = []\n",
    "MSE_validation = []\n",
    "MSE_test = []\n",
    "for each in lam_all:\n",
    "    MSE_training_here = 0 \n",
    "    MSE_validation_here = 0 \n",
    "    MSE_test_here = 0\n",
    "    for train_index, test_index in kf.split(y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        theta, t_stat = closed_form_2(X_train, y_train, lam=each)\n",
    "        y_predict = X_train @ theta[1:] + theta[0]\n",
    "        MSE_training_here += mean_squared_error(y_train, y_predict)\n",
    "        y_predict = X_test @ theta[1:] + theta[0]\n",
    "        MSE_validation_here += mean_squared_error(y_test, y_predict)\n",
    "        MSE_test_here += mean_squared_error(testing_set[\"Temp\"].values, testing_set.loc[:, \"MEI\":\"Aerosols\"].values @ theta[1:] + theta[0])\n",
    "    \n",
    "    MSE_training.append(MSE_training_here / 5)\n",
    "    MSE_validation.append(MSE_validation_here / 5)\n",
    "    MSE_test.append(MSE_test_here / 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(MSE_training, 'g*', label=\"training set\")\n",
    "ax.plot(MSE_validation, 'r*', label=\"validation set\")\n",
    "ax.plot(MSE_test, 'b*', label=\"testing set\")\n",
    "ax.set_xlabel(\"lambda\")\n",
    "ax.set_ylabel(\"MSE\")\n",
    "ax.set_xticks(np.arange(len(lam_all)))\n",
    "ax.set_xticklabels(lam_all)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE is minimized in validation set when lambda equals to 0. Lambda = 0 also performs well in testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3 — Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. From Problem 1, you can know which variables are significant, therefore you can use less variables to train model. For example, remove highly correlated and redundant features. You can propose a workflow to select feature.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow:\n",
    "* Find the features with high correlation coefficients.\n",
    "* Calculate the importance of these features using variance analyses, Pearson correlation and tree-based feature selection.\n",
    "* Drop the features which are highly correlated with others (from step1) and not so important (from step2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Train a better model than the model in Problem 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are eight initial features. First, I will find the features with high correlation coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>MEI</th>\n",
       "      <th>CO2</th>\n",
       "      <th>CH4</th>\n",
       "      <th>N2O</th>\n",
       "      <th>CFC-11</th>\n",
       "      <th>CFC-12</th>\n",
       "      <th>TSI</th>\n",
       "      <th>Aerosols</th>\n",
       "      <th>Temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1983</td>\n",
       "      <td>5</td>\n",
       "      <td>2.556</td>\n",
       "      <td>345.96</td>\n",
       "      <td>1638.59</td>\n",
       "      <td>303.677</td>\n",
       "      <td>191.324</td>\n",
       "      <td>350.113</td>\n",
       "      <td>1366.1024</td>\n",
       "      <td>0.0863</td>\n",
       "      <td>0.109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1983</td>\n",
       "      <td>6</td>\n",
       "      <td>2.167</td>\n",
       "      <td>345.52</td>\n",
       "      <td>1633.71</td>\n",
       "      <td>303.746</td>\n",
       "      <td>192.057</td>\n",
       "      <td>351.848</td>\n",
       "      <td>1366.1208</td>\n",
       "      <td>0.0794</td>\n",
       "      <td>0.118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Month    MEI     CO2      CH4      N2O   CFC-11   CFC-12        TSI  \\\n",
       "0  1983      5  2.556  345.96  1638.59  303.677  191.324  350.113  1366.1024   \n",
       "1  1983      6  2.167  345.52  1633.71  303.746  192.057  351.848  1366.1208   \n",
       "\n",
       "   Aerosols   Temp  \n",
       "0    0.0863  0.109  \n",
       "1    0.0794  0.118  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = training_set.loc[:, \"MEI\":\"Aerosols\"]\n",
    "y = training_set[\"Temp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.         -0.04114717 -0.0334193  -0.05081978  0.06900044  0.00828554\n",
      "  -0.15449192  0.34023779]\n",
      " [-0.04114717  1.          0.87727963  0.97671982  0.51405975  0.85268963\n",
      "   0.17742893 -0.3561548 ]\n",
      " [-0.0334193   0.87727963  1.          0.89983864  0.77990402  0.96361625\n",
      "   0.24552844 -0.26780919]\n",
      " [-0.05081978  0.97671982  0.89983864  1.          0.52247732  0.86793078\n",
      "   0.19975668 -0.33705457]\n",
      " [ 0.06900044  0.51405975  0.77990402  0.52247732  1.          0.86898518\n",
      "   0.27204596 -0.0439212 ]\n",
      " [ 0.00828554  0.85268963  0.96361625  0.86793078  0.86898518  1.\n",
      "   0.25530281 -0.22513124]\n",
      " [-0.15449192  0.17742893  0.24552844  0.19975668  0.27204596  0.25530281\n",
      "   1.          0.05211651]\n",
      " [ 0.34023779 -0.3561548  -0.26780919 -0.33705457 -0.0439212  -0.22513124\n",
      "   0.05211651  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(np.corrcoef(X.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above result, we can see that there are high relationship among CO2, CH4, N2O, CFC-11 and CFC-12 variables. Next, I will calculate the importance of these features using variance analyses, Pearson correlation and tree-based feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance: \n",
      " [8.61185079e-01 1.30405741e+02 2.07839066e+03 2.25637109e+01\n",
      " 4.38931351e+02 3.47422945e+03 1.60460862e-01 8.97671505e-04]\n"
     ]
    }
   ],
   "source": [
    "# Filter method 1: Removing features with low variance\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "selector = VarianceThreshold(threshold=3).fit(training_set.loc[:, \"MEI\":\"Aerosols\"])\n",
    "print(\"Variance: \\n\", selector.variances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corr: \n",
      " [0.1724707512381389, 0.7885292093308759, 0.703255021650043, 0.7786389297717538, 0.40771028965805495, 0.6875575482940205, 0.2433826874052623, -0.38491374619822105]\n",
      "p_value: \n",
      " [0.0035501728764938175, 1.7415402024355552e-61, 1.1072852344421367e-43, 5.078803889433899e-59, 8.441358577157838e-13, 4.400163480418584e-41, 3.383636845955244e-05, 1.8334173019513696e-11]\n"
     ]
    }
   ],
   "source": [
    "# Filter method 2: Univariate feature selection——Pearson Correlation\n",
    "from scipy.stats import pearsonr\n",
    "corr, corr_p = [], []\n",
    "for pos in range(X.shape[1]):\n",
    "    result = pearsonr(X.iloc[:, pos], y)\n",
    "    corr.append(result[0])\n",
    "    corr_p.append(result[1])\n",
    "    \n",
    "print(\"corr: \\n\", corr)\n",
    "print(\"p_value: \\n\", corr_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances: \n",
      " [0.06467665 0.14493016 0.07114295 0.40576144 0.10165987 0.12274069\n",
      " 0.03715863 0.05192961]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# Embedded method: Tree-based feature selection\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "clf = ExtraTreesRegressor()\n",
    "clf = clf.fit(X, y)\n",
    "print(\"Feature importances: \\n\", clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MEI', 'CO2', 'CH4', 'N2O', 'CFC-11', 'CFC-12', 'TSI', 'Aerosols'], dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above result, we can see that N2O is the best feature among CO2, CH4, N2O, CFC-11 and CFC-12. Thus, I will drop the other four features. MEI, N20, TSI, Aerosols are the features finally choosed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient:\n",
      " [-1.16226858e+02  6.41857556e-02  2.53197457e-02  7.94902798e-02\n",
      " -1.70173707e+00] \n",
      " T statistics:\n",
      " [-5.74725299  9.64938883 19.30691076  5.34374748 -7.80628224] \n",
      "\n",
      "The model R2 on the training set and the testing set are 0.726132 and 0.453186.\n"
     ]
    }
   ],
   "source": [
    "feature = ['MEI', 'N2O', 'TSI', 'Aerosols']\n",
    "theta, t_stat = closed_form_1(training_set.loc[:, feature], training_set[\"Temp\"])\n",
    "y_predict = training_set.loc[:, feature] @ theta[1:] + theta[0]\n",
    "R2_training = R2(training_set[\"Temp\"], y_predict)\n",
    "\n",
    "y_predict = testing_set.loc[:, feature] @ theta[1:] + theta[0]\n",
    "R2_testing = R2(testing_set[\"Temp\"], y_predict)\n",
    "print(\"Coefficient:\\n\", theta, \"\\n T statistics:\\n\", t_stat, \"\\n\")\n",
    "print(\"The model R2 on the training set and the testing set are %f and %f.\" % (R2_training, R2_testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.         -0.05081978 -0.15449192  0.34023779]\n",
      " [-0.05081978  1.          0.19975668 -0.33705457]\n",
      " [-0.15449192  0.19975668  1.          0.05211651]\n",
      " [ 0.34023779 -0.33705457  0.05211651  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(np.corrcoef(training_set.loc[:, feature].values.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After feature selection, we can see that the remaining features are all significant and the correlation coefficient between them is low. Besides the R square of testing data also increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4 — Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient descent algorithm is an iterative process that takes us to the minimum of a function. Please write down the iterative expression for updating the solution of linear model and implement it using Python or Matlab in gradientDescent function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothesis:\n",
    "\\begin{array}{ll} \\mbox{} & h_{\\theta}(x) = \\theta_0 x_0 + \\theta_1 x_1 + ... + \\theta_n x_n\n",
    "\\end{array}\n",
    "\n",
    "Cost function:\n",
    "\\begin{array}{ll} \\mbox{} & J (\\theta_0, \\theta_1, ..., \\theta_n) = \\frac{1}{2m} \\sum_{i=1}^m (h_{\\theta}(x^{(i)}) -y^{(i)})^2\n",
    "\\end{array}\n",
    "\n",
    "Batch Gradient Descent:\n",
    "\\begin{array}{ll} \\mbox{Repeat} \n",
    "& \\theta_j = \\theta_j - \\alpha \\frac{\\partial}{\\partial \\theta_j} J (\\theta_0, \\theta_1, ..., \\theta_n), j=0, 1,..., n\n",
    "\\end{array}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(X): # If not normalization, the value will be too large when updating the theta.  \n",
    "\n",
    "    maxX = np.max(X, axis=0)     \n",
    "    minX = np.min(X, axis=0)     \n",
    "    \n",
    "    return (X - minX) /(maxX-minX)\n",
    "\n",
    "def gradientDescent(X, y, theta=None, alpha=0.2, max_itor=50000, eps=10**-8):\n",
    "    # X: features, (n, k) array\n",
    "    # y: targets, (n, ) array\n",
    "    # theta: initial parameter, (k, ) array\n",
    "    n, k = X.shape\n",
    "    itor = 0\n",
    "    err1, err2 = 0, 0\n",
    "    \n",
    "    if theta is None:\n",
    "        theta = np.ones(k) * 0.1\n",
    "    \n",
    "    while True:\n",
    "        itor += 1\n",
    "        if itor > max_itor:\n",
    "            print(\"reach maximal iteration\")\n",
    "            break\n",
    "\n",
    "        theta = theta - alpha * ( X @ theta - y) @ X / n\n",
    "        err2 = np.sum(X @ theta - y)\n",
    "        \n",
    "        if abs(err2 - err1) < eps:\n",
    "            break\n",
    "        \n",
    "        err1 = err2\n",
    "        \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta: \n",
      " [ 7.62311435  0.18684724  0.37635523  0.07476875 -0.2577572 ]\n"
     ]
    }
   ],
   "source": [
    "X = training_set.loc[:, feature].values\n",
    "X_norm = normalization(X)\n",
    "X_norm = np.hstack((0.01*np.ones([X_norm.shape[0], 1]), X_norm))\n",
    "y = training_set[\"Temp\"].values\n",
    "theta = gradientDescent(X_norm, y)\n",
    "theta[0] = theta[0] * 100\n",
    "print(\"theta: \\n\", theta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
